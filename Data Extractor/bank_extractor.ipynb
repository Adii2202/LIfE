{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1b3d50e7",
   "metadata": {},
   "source": [
    "CODE FOR EXTRACTING TEXT AND TABLES FROM THE PDF FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0616c7d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables saved successfully to :  output.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import tabula\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        all_text = \"\"\n",
    "        for page_number, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            all_text += text\n",
    "    return all_text\n",
    "\n",
    "def save_text_file(text , output_txt_file):\n",
    "    with open(output_txt_file, \"w\" , encoding='utf-8') as text_file:\n",
    "      text_file.write(text)\n",
    "\n",
    "def extract_table(pdf, csv, type):\n",
    "    tables = camelot.read_pdf(pdf, flavor='lattice', pages='all', split_text=True)\n",
    "    df = pd.DataFrame()\n",
    "    header_set = set() # to record the column name\n",
    "    for i,table in enumerate(tables):\n",
    "        table_df = table.df\n",
    "        if not table_df.empty:\n",
    "            first_row = tuple(table_df.iloc[0])\n",
    "            header_set.add(first_row)\n",
    "            table_df.columns = first_row\n",
    "            if i>0:\n",
    "                table_df.columns=df.columns #always set column names equal to the start page columns\n",
    "            df = pd.concat([df,table_df], ignore_index=True, axis=0) #row-wise concat\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df[~df.apply(lambda row: all(row == df.columns), axis=1)] # remov repeating column name(if any)\n",
    "    df.to_csv(csv, index=False)\n",
    "    print(\"Tables saved successfully to : \", csv)\n",
    "    \n",
    "def extract_table_HDFC(pdf,csv):\n",
    "    tables = tabula.read_pdf(pdf, pages='all', multiple_tables=True)\n",
    "    if len(tables) > 0:\n",
    "        df = pd.DataFrame()\n",
    "        for i,table in enumerate(tables):\n",
    "            table = table.dropna(axis=0, how='all')\n",
    "            table = table.dropna(axis=1, how='all')\n",
    "            first_row = table.columns\n",
    "            table.columns = first_row\n",
    "            if i>0:\n",
    "                table.columns = df.columns\n",
    "            df = pd.concat([df,table], ignore_index=True, axis=0)\n",
    "    df = df.dropna(subset=[df.columns[0]])\n",
    "    df.to_csv(csv, index=False)\n",
    "    print(\"Tables saved successfully to : \",csv)\n",
    "\n",
    "def main():\n",
    "    pdf = 'HDFC.pdf'\n",
    "    type = 'HDFC'\n",
    "    text = 'text_output.txt'\n",
    "    csv = 'output.csv'\n",
    "    text_data = extract_text_from_pdf(pdf)\n",
    "    save_text_file(text_data , text)\n",
    "    if (type == 'HDFC'):\n",
    "        extract_table_HDFC(pdf,csv)\n",
    "    else:\n",
    "        extract_table(pdf,csv,type)\n",
    "main()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "899dff52",
   "metadata": {},
   "source": [
    "CODE FOR EXTRACTING IMPORTANT DETAILS LIKE : NAME , EMAIL , FROM_DATE AND TO_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e0cbdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMER NAME :  Rohanshriramgaikwad\n",
      "EMAIL ID :  rohan1618033@gmail.com\n",
      "FROM DATE :  11/08/2023\n",
      "TO DATE :  11/09/2023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def details_extract(txt_file,type):\n",
    "    with open(txt_file,'r') as file:\n",
    "        text = file.read()\n",
    "    # Remove (cid:n) occurrences where 'n' is any number\n",
    "    text = re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "    text = text.lower()\n",
    "    customer = r'(?:customer\\s*:|customer name\\s*:|account name\\s*:|mr.\\s*|mrs.\\s*|miss\\s*|ms.\\s*|mas\\s*)(.*)\\n'\n",
    "    email = r'(?:email\\s*:\\s*|email id\\s*:\\s*)(.*)\\n'\n",
    "    from_date = r'\\b(?:from\\s*:\\s*|from\\s*|for period\\s*:\\s*)(\\d{1,2}[/\\s-]\\d{1,2}[/\\s-]\\d{2,4}|\\d{1,2}\\s[A-Za-z]{3}\\s\\d{2,4})'\n",
    "    to_date = r'(?:to\\s*:\\s*|to:|to\\s*)(\\d{1,2}[/\\s-]\\d{1,2}[/\\s-]\\d{2,4}|\\d{1,2} [A-Za-z]{3} \\d{2,4})'\n",
    "    \n",
    "    customer_match = re.search(customer, text)\n",
    "    customer_name = customer_match.group(1) if customer_match else None\n",
    "    if customer_name:\n",
    "        customer_name = customer_name.title()\n",
    "    \n",
    "    email_match = re.search(email, text)\n",
    "    email_id = email_match.group(1) if email_match else None\n",
    "    \n",
    "    from_match = re.search(from_date, text)\n",
    "    from_res = from_match.group(1) if from_match else None\n",
    "    if from_res:\n",
    "        from_res = from_res.title()\n",
    "    \n",
    "    to_match = re.search(to_date,text)\n",
    "    to = to_match.group(1) if to_match else None\n",
    "    if to:\n",
    "        to = to.title()\n",
    "    if (customer_name == None or re.search(r'[0-9]',customer_name)):\n",
    "        customer_name = 'Name not found'\n",
    "    if (email_id == None): \n",
    "        email_id = 'Email id not found'\n",
    "    print('CUSTOMER NAME : ',customer_name)\n",
    "    print('EMAIL ID : ',email_id)\n",
    "    print('FROM DATE : ',from_res)\n",
    "    print('TO DATE : ',to)\n",
    "    \n",
    "def main():\n",
    "    txt_file = 'text_output.txt'\n",
    "    type = 'HDFC'\n",
    "    details_extract(txt_file,type)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129317e3",
   "metadata": {},
   "source": [
    " CODE FOR STANDARDISING COLUMNS OF EXTRACTED TABLE \n",
    " COLUMN NAMES : DATE , DESCRIPTION / ((NARRATION)) , AMOUNT (DR,CR) , BALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date                                 Narration   Amount   Balance\n",
      "0   2023-08-11  NEFT CR-YESB0000001-ZERODHA BROKING LTD-  1667.53  14748.63\n",
      "1   2023-08-11   1008545301 TATA MOTORS LTD ORD DIV22 23     4.00  14752.63\n",
      "2   2023-08-12  UPI-VRINDAVAN DAIRY FIRM-PAYTMQR28100505   -54.00  14698.63\n",
      "3   2023-08-12  UPI-GIRNAR SWEETS-PAYTMQR2810050501012FC   -68.00  14630.63\n",
      "4   2023-08-13  UPI-PALAVA TFG1-PAYTMQR28100505010163ZCU  -390.00  14240.63\n",
      "..         ...                                       ...      ...       ...\n",
      "116 2023-09-09  UPI-AMAZON SELLER SERVIC-AMAZONSELLERSER  -399.00  15981.13\n",
      "117 2023-09-09  UPI-AMAZON SELLER SERVIC-AMAZONSELLERSER   399.00  16380.13\n",
      "118 2023-09-11                       UPI-ZERODHA BROKING -1000.00  15380.13\n",
      "119 2023-09-11   UPI-M R C CANTEEN-PAYTMQR281005050101BA   -30.00  15350.13\n",
      "120 2023-09-11  UPI-BHARAT BAU RAJPUT-PAYTMQRU35R2Y9RXU@  -195.00  15155.13\n",
      "\n",
      "[121 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rename_to_narration(df):\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            threshold = 15\n",
    "            has_large_alphanum = df[column].astype(str).str.count('[A-Za-z0-9]').max() >= threshold\n",
    "            if has_large_alphanum:\n",
    "                df = df.rename(columns = {column: 'Narration'},inplace=True)\n",
    "        except(ValueError, TypeError):\n",
    "            continue\n",
    "\n",
    "def rename_to_date(df):\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            if df[column].apply(lambda x: parser.parse(str(x), fuzzy=True, dayfirst=True)).notna().all():\n",
    "                df = df.rename(columns = {column:'Date'},inplace=True)\n",
    "        except(ValueError, TypeError):\n",
    "            continue\n",
    "\n",
    "def rename_to_balance(df):\n",
    "    pattern = r'^[0-9,.]+$'\n",
    "    for column in df.columns:\n",
    "        try:    \n",
    "            if df[column].apply(lambda x: isinstance(x, str) and bool(re.match(pattern, x)) if not pd.isna(x) else False).all():\n",
    "                df.rename(columns = {column: 'Balance'},inplace = True)\n",
    "        except(ValueError, TypeError):\n",
    "            continue\n",
    "\n",
    "def rename_credit_debit(df):\n",
    "    for i in range(0,30):\n",
    "        if i > 29:\n",
    "            break\n",
    "        df['Balance'] = df['Balance'].astype(str).str.replace(',', '', regex=True).astype(float)\n",
    "        value = df['Balance'][i+1] - df['Balance'][i]\n",
    "        if value > 0 : \n",
    "            for column in df.columns:\n",
    "                try:\n",
    "                    df[column] = df[column].astype(str).str.replace(',','',regex=True).astype(float)\n",
    "                except (ValueError,TypeError):\n",
    "                    continue\n",
    "                if value == df[column][i+1]:\n",
    "                    df.rename(columns = {column: 'Credit'},inplace = True)\n",
    "        else:\n",
    "            for column in df.columns:\n",
    "                try:\n",
    "                    df[column] = df[column].astype(str).str.replace(',','',regex=True).astype(float)\n",
    "                except (ValueError,TypeError):\n",
    "                    continue\n",
    "                if value == -(df[column][i+1]):\n",
    "                    df.rename(columns = {column: 'Debit'},inplace = True)\n",
    "\n",
    "def standardise_table(df,type,csv):\n",
    "    req_col = ['Date', 'Narration', 'Amount', 'Balance']\n",
    "    \n",
    "    if (type == 'HDFC' or type == 'SBI' or type == 'AXIS'):           \n",
    "        df.fillna(0.0, inplace=True)\n",
    "        df['Amount'] = df['Credit'] - df['Debit']\n",
    "        df['Balance'] = df['Balance'].astype(str).str.replace(',', '', regex=True).astype(float)\n",
    "        df['Date'] = df['Date'].apply(lambda x: parser.parse(x, dayfirst=True, fuzzy=True))\n",
    "        df = df[req_col]\n",
    "        df1 = df\n",
    "        df1.to_csv(csv, index=False)\n",
    "        \n",
    "    elif (type == 'PNB'):\n",
    "        df.fillna(0.0, inplace=True)\n",
    "        df['Amount'] = df.apply(lambda row: -row['Amount'] if row['Type'] == 'DR' else row['Amount'], axis=1)\n",
    "        df['Balance'] = df['Balance'].astype(str).str.replace(',', '', regex=True).astype(float)\n",
    "        df['Date'] = df['Date'].apply(lambda x: parser.parse(x, dayfirst=True, fuzzy=True))\n",
    "        df = df[req_col]\n",
    "        df1 = df\n",
    "        df1.to_csv(csv, index=False)\n",
    "\n",
    "    elif (type == 'ICICI'):\n",
    "        df.fillna(0.0, inplace=True)\n",
    "        df['Amount'] = df.apply(lambda row: -row['Amount'] if row['Type'] == 'DR' else row['Amount'], axis=1)\n",
    "        df['Date'] = df['Date'].apply(lambda x: parser.parse(x, dayfirst=True, fuzzy=True))\n",
    "        df = df[['Date','Narration','Amount']]\n",
    "        df1 = df\n",
    "        df1.to_csv(csv, index=False)\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def main():\n",
    "    csv = 'output.csv'\n",
    "    type = 'HDFC'\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.dropna(subset=[df.columns[0]])\n",
    "    rename_to_narration(df)\n",
    "    rename_to_date(df)\n",
    "    df = df.dropna(subset=['Date']).reset_index(drop=True)\n",
    "    rename_to_balance(df)\n",
    "    if(type == 'HDFC' or type == 'SBI' or type == 'AXIS'): \n",
    "        rename_credit_debit(df)\n",
    "    df = standardise_table(df,type,csv)\n",
    "    df.to_excel('output.xlsx', index=False, na_rep='N/A', header=custom_header, index_label='ID')\n",
    "    print(df)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
